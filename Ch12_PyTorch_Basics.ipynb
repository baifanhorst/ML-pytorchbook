{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfa2880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f197189",
   "metadata": {},
   "source": [
    "## Create tensor from list or numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07968ac1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor(1)\n",
      "1\n",
      "[1, 2, 3]\n",
      "[1 2 3]\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a list\n",
    "a = [1,2,3]\n",
    "t_a = torch.tensor(a)\n",
    "print(t_a)\n",
    "print(t_a[0])\n",
    "# Fetch an element\n",
    "print(t_a[0].item())\n",
    "# Convert to a list\n",
    "print(t_a.tolist())\n",
    "# Convert to a numpy array\n",
    "print(t_a.numpy())\n",
    "# The default type is int64\n",
    "print(t_a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ade72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6], dtype=torch.int32)\n",
      "int32\n",
      "torch.int32\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor from a numpy array\n",
    "b = np.array([4,5,6])\n",
    "t_b = torch.tensor(b)\n",
    "print(t_b)\n",
    "# Note that the type is int32\n",
    "print(b.dtype)\n",
    "print(t_b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7696a",
   "metadata": {},
   "source": [
    "About types:   \n",
    "The default element type after convertion from a list and from an array are different. The reason is the difference between the two sources. The default type of the integer elements in the list 'a' is int64 (This will show as 'int' if we print its type. In fact, this default type depends on platform and python version). On the other hand, the default type of the elements in the numpy array 'b' is int32, at least on this laptop. torch.tensor does not change the data types. It converts the original type to the corresponding type in torch: int64-->torch.int64, int32-->torch.int32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d206df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# We can specify the data type manually\n",
    "c = np.array([4,5,6], dtype=np.int64)\n",
    "t_c = torch.tensor(c)\n",
    "# When printing t_c, the data type of the tensor is not shown. This is because it has the default data type, which is torch.int64\n",
    "print(t_c)\n",
    "print(t_c.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4e1bd9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "torch.int64\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Tensor whose elements are all 1's\n",
    "t_ones = torch.ones(2,3)\n",
    "print(t_ones)\n",
    "print(t_ones.dtype)\n",
    "\n",
    "# Choose the type manually\n",
    "# int64\n",
    "t_ones = torch.ones((2,3), dtype=torch.int64)\n",
    "print(t_ones)\n",
    "print(t_ones.dtype)\n",
    "# float64\n",
    "t_ones = torch.ones((2,3), dtype=torch.float64)\n",
    "print(t_ones)\n",
    "print(t_ones.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "477964f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4436, 0.6921, 0.8738],\n",
      "        [0.1679, 0.3789, 0.4707]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# A random tensor\n",
    "# Each element is sampled uniformly between 0 and 1\n",
    "t_rand = torch.rand(2,3)\n",
    "print(t_rand)\n",
    "print(t_rand.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8937eef",
   "metadata": {},
   "source": [
    "## Change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "046ab292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(t_a.dtype)\n",
    "t_a_int32 = t_a.to(torch.int32)\n",
    "print(t_a_int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89622efa",
   "metadata": {},
   "source": [
    "## Change shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "326bcd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2194, 0.8422, 0.9596],\n",
      "        [0.4180, 0.2855, 0.7158]])\n",
      "tensor([[0.2194, 0.4180],\n",
      "        [0.8422, 0.2855],\n",
      "        [0.9596, 0.7158]])\n",
      "torch.Size([2, 3])\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "t = torch.rand(2,3)\n",
    "t_transpose = torch.transpose(t, 0, 1) # Switch dimension 0 and 1.\n",
    "print(t)\n",
    "print(t_transpose)\n",
    "print(t.shape)\n",
    "print(t_transpose.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3687d073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1., 10.],\n",
      "        [ 1.,  1.]])\n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1., 10.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.transpose does not copy the original tensor\n",
    "# It just provides another way of indexing\n",
    "t = torch.ones(2,3)\n",
    "t_transpose = torch.transpose(t, 0, 1)\n",
    "print(t)\n",
    "print(t_transpose)\n",
    "t_transpose[1,1] = 10\n",
    "print(t_transpose)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f06e00e2-bdf5-4857-9f69-e6d70c5806de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1., 10.,  1.]])\n",
      "tensor([[ 1.,  1.],\n",
      "        [ 1., 10.],\n",
      "        [ 1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "# Another way of tranposition\n",
    "t = torch.ones(2,3)\n",
    "t_transpose = t.transpose(0,1)\n",
    "print(t)\n",
    "print(t_transpose)\n",
    "# This method does not create a new tensor\n",
    "t_transpose[1,1] = 10\n",
    "print(t)\n",
    "print(t_transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97de232d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1., 1.])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([100.,   1.,   1.,   1.,   1.,   1.])\n",
      "tensor([[100.,   1.,   1.],\n",
      "        [  1.,   1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "t = torch.ones(2*3)\n",
    "t_reshape = t.reshape(2,3)\n",
    "print(t)\n",
    "print(t_reshape)\n",
    "# This method does not create a new tensor\n",
    "t_reshape[0,0] = 100\n",
    "print(t)\n",
    "print(t_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4a8ac03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 1, 4, 1])\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 1, 4, 1])\n",
      "torch.Size([1, 2, 4, 1])\n",
      "torch.Size([1, 2, 1, 4])\n",
      "torch.Size([2, 4, 1])\n",
      "torch.Size([1, 2, 1, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# Squeeze: remove dimensions of size 1\n",
    "t = torch.zeros(1,2,1,4,1)\n",
    "# Remove all dimensions of size 1\n",
    "t_squeeze = torch.squeeze(t) \n",
    "print(t.shape)\n",
    "print(t_squeeze.shape)\n",
    "# Remove the size 1 dimension at the chosen dimensions\n",
    "print(torch.squeeze(t, 0).shape)\n",
    "print(torch.squeeze(t, 2).shape)\n",
    "print(torch.squeeze(t, 4).shape)\n",
    "print(torch.squeeze(t, (0, 2)).shape)\n",
    "# If the chosen dimension is not of size 1, nothing will happen\n",
    "print(torch.squeeze(t, 1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49e3775",
   "metadata": {},
   "source": [
    "## Mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0c30d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5153, -0.4414],\n",
      "        [-0.1939,  0.4694],\n",
      "        [-0.9414,  0.5997],\n",
      "        [-0.2057,  0.5087],\n",
      "        [ 0.1390, -0.1224]])\n",
      "tensor([[ 0.8590,  0.7056],\n",
      "        [-0.3406, -1.2720],\n",
      "        [-1.1948,  0.0250],\n",
      "        [-0.7627,  1.3969],\n",
      "        [-0.3245,  0.2879]])\n"
     ]
    }
   ],
   "source": [
    "# Setting the random seed to a fixed value ensures that the same sequence of random numbers will be generated every time the code is run.\n",
    "torch.manual_seed(1)\n",
    "# Create a tensor whose entries are in [-1, 1)\n",
    "# torch.rand returns a tensor whose entries are from the uniform distribution on [0,1)\n",
    "t1 = 2 * torch.rand(5,2) - 1 \n",
    "print(t1)\n",
    "# Create a tensor whose entries follow the standard normal distribution\n",
    "t2 = torch.normal(mean=0, std=1, size=(5,2))\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89ff95d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4426, -0.3114],\n",
      "        [ 0.0660, -0.5970],\n",
      "        [ 1.1249,  0.0150],\n",
      "        [ 0.1569,  0.7107],\n",
      "        [-0.0451, -0.0352]])\n",
      "tensor([[ 0.4426, -0.3114],\n",
      "        [ 0.0660, -0.5970],\n",
      "        [ 1.1249,  0.0150],\n",
      "        [ 0.1569,  0.7107],\n",
      "        [-0.0451, -0.0352]])\n",
      "tensor([[ 0.4426, -0.3114],\n",
      "        [ 0.0660, -0.5970],\n",
      "        [ 1.1249,  0.0150],\n",
      "        [ 0.1569,  0.7107],\n",
      "        [-0.0451, -0.0352]])\n"
     ]
    }
   ],
   "source": [
    "# 3 ways of elementwise product\n",
    "print( t1 * t2)\n",
    "print( torch.mul(t1, t2))\n",
    "print( torch.multiply(t1, t2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72d007cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1373,  0.2028])\n",
      "tensor([ 0.0369,  0.1378, -0.1709,  0.1515,  0.0083])\n",
      "tensor(0.0327)\n"
     ]
    }
   ],
   "source": [
    "# Mean along a given axis\n",
    "print(torch.mean(t1, axis=0))\n",
    "print(torch.mean(t1, axis=1))\n",
    "# Mean of all entries\n",
    "print(torch.mean(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbad94d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1312,  0.3860, -0.6267, -1.0096, -0.2943],\n",
      "        [ 0.1647, -0.5310,  0.2434,  0.8035,  0.1980],\n",
      "        [-0.3855, -0.4422,  1.1399,  1.5558,  0.4781],\n",
      "        [ 0.1822, -0.5771,  0.2585,  0.8676,  0.2132],\n",
      "        [ 0.0330,  0.1084, -0.1692, -0.2771, -0.0804]])\n",
      "tensor([[ 0.1312,  0.3860, -0.6267, -1.0096, -0.2943],\n",
      "        [ 0.1647, -0.5310,  0.2434,  0.8035,  0.1980],\n",
      "        [-0.3855, -0.4422,  1.1399,  1.5558,  0.4781],\n",
      "        [ 0.1822, -0.5771,  0.2585,  0.8676,  0.2132],\n",
      "        [ 0.0330,  0.1084, -0.1692, -0.2771, -0.0804]])\n",
      "tensor([[ 0.1312,  0.3860, -0.6267, -1.0096, -0.2943],\n",
      "        [ 0.1647, -0.5310,  0.2434,  0.8035,  0.1980],\n",
      "        [-0.3855, -0.4422,  1.1399,  1.5558,  0.4781],\n",
      "        [ 0.1822, -0.5771,  0.2585,  0.8676,  0.2132],\n",
      "        [ 0.0330,  0.1084, -0.1692, -0.2771, -0.0804]])\n",
      "tensor([[ 1.7453,  0.3392],\n",
      "        [-1.6038, -0.2180]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "# using torch.matmul\n",
    "print( torch.matmul(t1, torch.transpose(t2, 0, 1)) )\n",
    "# using @\n",
    "print(t1 @ torch.transpose(t2, 0, 1))\n",
    "\n",
    "# To transpose t2, we can also use t2.transpose(0, 1)\n",
    "print( torch.matmul(t1, t2.transpose(0, 1)) )\n",
    "print( torch.matmul(t1.transpose(0, 1), t2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ee3274c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5165)\n",
      "tensor(2.1417)\n",
      "torch.Size([5, 2])\n",
      "tensor([1.9953, 2.1417])\n",
      "tensor([0.9566, 0.6632, 1.5412, 0.7145, 0.2615])\n"
     ]
    }
   ],
   "source": [
    "# Norms\n",
    "# Frobenius norm (the default norm, the square root of the sum of the squares of the elements)\n",
    "print( torch.linalg.norm(t1) )\n",
    "# L1 norm (see the next cell for its definition)\n",
    "print( torch.linalg.norm(t1, ord=1) )\n",
    "# L1 norm along a specific dimension\n",
    "print( t1.shape )\n",
    "print( torch.linalg.norm(t1, ord=1, dim=0) )\n",
    "print( torch.linalg.norm(t1, ord=1, dim=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d7074d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frobenius direct calculation tensor(1.5165)\n",
      "Frobenius tensor(1.5165)\n",
      "Sum of absolute values tensor(2.1417)\n",
      "L1 tensor(2.1417)\n"
     ]
    }
   ],
   "source": [
    "# Validation of the norms\n",
    "# Validate the Frobenius norm\n",
    "print(\"Frobenius direct calculation\", torch.sqrt(torch.sum(t1 * t1)))\n",
    "print(\"Frobenius\", torch.linalg.norm(t1) )\n",
    "\n",
    "# Validate the L1 norm\n",
    "# The L1 norm is not the sum of the absolute values of all elements\n",
    "# The L1 norm is :torch.max(torch.sum(torch.abs(t1), dim=0))\n",
    "# i.e.: max(sum(abs(t1), dim=0))\n",
    "# Namely, we take absolute values of all elements, them add along the first dimension (along each column), then we select the maximum sum as the L1 norm\n",
    "print(\"Sum of absolute values\", torch.max( torch.sum( torch.abs(t1), dim=0 ) )  )\n",
    "print(\"L1\", torch.linalg.norm(t1, ord=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67dd9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "# Another example of L1 norm\n",
    "t = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "print(t)\n",
    "print(torch.linalg.norm(t, ord=1))\n",
    "# Obviously, the result is not the sum of all absolute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f394d",
   "metadata": {},
   "source": [
    "## Split and join tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "741358ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4828, 0.0281, 0.1782, 0.2079, 0.2861, 0.8555])\n",
      "(tensor([0.4828, 0.0281]), tensor([0.1782, 0.2079]), tensor([0.2861, 0.8555])) \n",
      "\n",
      "(tensor([0.4828, 0.0281]), tensor([0.1782, 0.2079]), tensor([0.2861, 0.8555])) \n",
      "\n",
      "(tensor([0.3366, 0.1264, 0.6924, 0.6601]), tensor([0.8238, 0.2413, 0.6084]))\n",
      "(tensor([0.3180, 0.3877, 0.1015]), tensor([0.2721, 0.3469, 0.7138]), tensor([0.5913]))\n",
      "(tensor([0.6235, 0.9991]), tensor([0.9873, 0.8410]), tensor([0.5159, 0.1541]), tensor([0.8908]))\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(6)\n",
    "print(t)\n",
    "# Split into three parts\n",
    "print( torch.chunk(t, 3), '\\n' )\n",
    "# When the number of chunks cannot divide the total number of elements, the result can be weird\n",
    "# The following code tries to divide t into 4 parts. However, the result is a list of 3 tensors\n",
    "# The behavior of torch.chunk() in this situation is to create as many equal-sized chunks \n",
    "# as possible without leaving any elements unused. \n",
    "# With 6 elements, it can create 3 chunks of 2 elements each, \n",
    "# which is the closest it can get to the requested 4 chunks while maintaining equal sizes.\n",
    "print( torch.chunk(t, 4), '\\n' )\n",
    "\n",
    "# The last tensor of the split may be smaller that the others\n",
    "print( torch.chunk(torch.rand(7), 2) )\n",
    "print( torch.chunk(torch.rand(7), 3) )\n",
    "print( torch.chunk(torch.rand(7), 4) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94febdab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9595, 0.0677, 0.1103, 0.4830, 0.2296])\n",
      "(tensor([0.9595, 0.0677, 0.1103]), tensor([0.4830, 0.2296]))\n",
      "(tensor([0.9595, 0.0677]), tensor([0.1103, 0.4830]), tensor([0.2296]))\n"
     ]
    }
   ],
   "source": [
    "# Specify split size of each chunk\n",
    "t = torch.rand(5)\n",
    "print(t)\n",
    "print( torch.split(t, split_size_or_sections=[3,2]) )\n",
    "# Specify the size of all chunks except for the last one, which may be smaller\n",
    "print( torch.split(t, split_size_or_sections=2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d4b13915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0.])\n",
      "tensor([1., 1., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Concatenate\n",
    "A = torch.ones(3)\n",
    "B = torch.zeros(2)\n",
    "C = torch.cat([A,B], axis=0)\n",
    "print(A)\n",
    "print(B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25257c88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1.])\n",
      "tensor([0., 0., 0.])\n",
      "tensor([[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Stack\n",
    "A = torch.ones(3)\n",
    "B = torch.zeros(3)\n",
    "C = torch.stack([A,B], axis=1)\n",
    "print(A)\n",
    "print(B)\n",
    "print(C)\n",
    "C = torch.stack([A,B], axis=0)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d3098d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation from ChatGPT\n",
    "# torch.cat concatenates a sequence of tensors along an existing dimension\n",
    "# torch.stack concatenates a sequence of tensors along a new dimension\n",
    "# Therefore, C = torch.cat([A,B], axis=1) will not work, since the axis=1 does not exist\n",
    "# But torch.stack([A,B], axis=1) will work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "16d7b32c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3]])\n",
      "tensor([[4, 5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# In order to stack two row vectors using concatenation, we need to define them as 2D tensor\n",
    "E = torch.tensor([[1,2,3]])\n",
    "F = torch.tensor([[4,5,6]])\n",
    "G = torch.cat([E,F], axis=0)\n",
    "print(E)\n",
    "print(F)\n",
    "print(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8178085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]])\n",
      "torch.Size([2, 1, 3])\n",
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# However, in this situation, torch.stack will not give desired results since it always add a new dimension\n",
    "E = torch.tensor([[1,2,3]])\n",
    "F = torch.tensor([[4,5,6]])\n",
    "G = torch.stack([E,F], axis=0)\n",
    "print(G)\n",
    "print(G.shape)\n",
    "G = torch.stack([E,F], axis=1)\n",
    "print(G)\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0cc15-459c-41d7-a8f5-04daaf278f73",
   "metadata": {},
   "source": [
    "It is better to understand torch.stack from a algebraic view. The shape of E and F is both (1,3). 'torch.stack([E,F], axis=0)' adds a new dimension as the first dimension, so that the result has shape (2,1,3). Thus, G[0]==E, G[1]==F. 'torch.stack([E,F], axis=1)' adds a new dimension as the second dimension, so that the result has shape (1,2,3). In this case, G[:,0,:]==E and G[:,1,:]==F. See below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "434346fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True]])\n",
      "tensor([[True, True, True]])\n",
      "tensor([[True, True, True]])\n",
      "tensor([[True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "G = torch.stack([E,F], axis=0)\n",
    "print( G[0]==E )\n",
    "print( G[1]==F )\n",
    "\n",
    "G = torch.stack([E,F], axis=1)\n",
    "print( G[:,0,:]==E )\n",
    "print( G[:,1,:]==F )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b563d-2ec9-40c5-8004-16dae727781d",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "(1) Create tensors from list, numpy array.   \n",
    "(2) Change datatype.   \n",
    "(3) Transpose, reshape.   \n",
    "(4) Mathematical operations.    \n",
    "(5) Chunk, split.   \n",
    "(5) Concatenate, stack.    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
