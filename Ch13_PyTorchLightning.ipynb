{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5324de3",
   "metadata": {},
   "source": [
    "## MNIST image classification with PyTorchLightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9f8470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchmetrics\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21de4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To install pytorch lightning:\n",
    "# conda install lightning -c conda-forge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f4265",
   "metadata": {},
   "source": [
    "# Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96b64820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3333)\n",
      "tensor([1, 0, 1])\n",
      "tensor(0.3333)\n",
      "tensor(0.3333)\n"
     ]
    }
   ],
   "source": [
    "# In the following, we will use the accuracy metric from torchmetrics\n",
    "# Here is its most basic use\n",
    "acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "y = torch.Tensor([0,1,2])\n",
    "y_hat = torch.Tensor([0,0,0])\n",
    "print(acc(y, y_hat))\n",
    "# Here our prediction is of float rather than int. \n",
    "# torchmetrics interprets this as logits and automatically apply softmax\n",
    "acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=2)\n",
    "y = torch.Tensor([[1.0, 2.0], [1.0, -1.0], [-2.0, -1.0]])\n",
    "# According to this y, the prediction should be [1, 0, 1], the accuracy should be 1/3\n",
    "pred = torch.argmax(y, dim=1)\n",
    "print(pred)\n",
    "y_hat = torch.Tensor([0,0,0])\n",
    "print(acc(y, y_hat))\n",
    "print(acc(pred, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0109be2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3333)\n"
     ]
    }
   ],
   "source": [
    "# Another method to calculate accuracy, which is implemented in the following codes\n",
    "# The key steps are to use update() and compute()\n",
    "acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "y = torch.Tensor([0,1,2])\n",
    "y_hat = torch.Tensor([0,0,0])\n",
    "acc.update(y, y_hat)\n",
    "print(acc.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33b156e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "# The benefit of using update() and compute() is that \n",
    "# we can accumulate the true labels over several iteration\n",
    "# Imagin that there are two batches, each with 3 examples\n",
    "# For the first batch, only one example is predicted correctly.\n",
    "# For the second batch, two examples are predicted correctly.\n",
    "# So the overall accuracy is (1+2)/(3+3)=0.5\n",
    "# This can be achieved by using update() for each batch and use compute() at the end\n",
    "acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\n",
    "y = torch.Tensor([0,1,2])\n",
    "y_hat = torch.Tensor([0,0,0])\n",
    "acc.update(y, y_hat)\n",
    "y = torch.Tensor([0,0,2])\n",
    "y_hat = torch.Tensor([0,0,0])\n",
    "acc.update(y, y_hat)\n",
    "print(acc.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e7f3f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "(1, 2, 3)\n",
      "(1, 2)\n",
      "(1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "# Another basic python utility used below is the extraction of arguments for a function\n",
    "def my_func(a,b,c):\n",
    "    print(a,b,c)\n",
    "    \n",
    "x = [1,2,3]\n",
    "my_func(*x)\n",
    "# By using *x, the entries in x is extracted to pass to my_func\n",
    "# The number of elements in x must be the same as the number of arguments of my_func\n",
    "\n",
    "# A related utility is to put * in the function definition\n",
    "# In this case, the function accepts any number of inputs\n",
    "def my_func2(*args):\n",
    "    print(args)\n",
    "    \n",
    "my_func2(1,2,3)\n",
    "my_func2(1,2)\n",
    "\n",
    "# We can use the two methods together to achieve arbitrary number of inputs when these inputs are in a list.\n",
    "x = [1,2,3]\n",
    "my_func2(*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6cded4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(pl.LightningModule):\n",
    "    def __init__(self, image_shape=(1,28,28), hidden_units=(32,16)):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define three accuracies to keep track of the training process\n",
    "        self.accuracy_train = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.accuracy_valid = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        self.accuracy_test = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    "        \n",
    "        input_size = image_shape[0] * image_shape[1] * image_shape[2]\n",
    "        \n",
    "        # Define layers\n",
    "        # Except the output layer, each linear layer is followed by a ReLU layer\n",
    "        all_layers = []\n",
    "        all_layers.append(torch.nn.Flatten())\n",
    "        for num_unit in hidden_units:\n",
    "            all_layers.append(torch.nn.Linear(input_size, num_unit))\n",
    "            all_layers.append(torch.nn.ReLU())\n",
    "            input_size = num_unit\n",
    "        all_layers.append(torch.nn.Linear(hidden_units[-1], 10))\n",
    "        self.model = torch.nn.Sequential(*all_layers)\n",
    "        # This is essentially the same as Sequential(layer1, layer2, ...)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # There is a forward method in pl.LightningModule.\n",
    "        # We use self.model(X) to create an instance and call the forward method in pl.LightningModule.\n",
    "        y = self.model(X)\n",
    "        return y\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # The most important step in this function is to calculate the loss function\n",
    "        # This naturally requires calculation of prediction, or at least computing the logits\n",
    "        # When using a loss function in torch.nn, pay attention to the shapes of its input\n",
    "        X, y = batch\n",
    "        # Logits are outputs of the network before being transformed by softmax\n",
    "        logits = self(X)\n",
    "        loss = torch.nn.functional.cross_entropy(self(X), y)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        self.accuracy_train.update(pred, y)\n",
    "        # self.log() is a method in PyTorch Lightning that logs a given metric value\n",
    "        # The self.log() method takes two arguments:\n",
    "        # name (string): The name of the metric to log.\n",
    "        # value (tensor or float): The value of the metric to log.\n",
    "        # prog_bar=True: the metric value will be displayed on the progress bar \n",
    "        # during training and validation.\n",
    "        self.log(\"train_loss\", loss, prog_bar=True) #??\n",
    "        return loss\n",
    "    \n",
    "    def on_train_epoch_end(self):  \n",
    "\n",
    "        # on_train_epoch_end is a method in PyTorch Lightning \n",
    "        # that is called at the end of each training epoch. \n",
    "        # It allows you to perform some operations on the model \n",
    "        # and the training data after each epoch has completed.\n",
    "        \n",
    "        # Here, we calculate the training accuracy accumulated over all batches.\n",
    "        # Note that we don't specify prog_bar, so it takes it default value (False)\n",
    "        self.log(\"train_acc\", self.accuracy_train.compute())\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # This is almost the same as the training step\n",
    "        X, y = batch\n",
    "        logits = self(X)\n",
    "        loss = torch.nn.functional.cross_entropy(self(X), y)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        self.accuracy_valid.update(pred, y)\n",
    "        # The validation loss and accuracy are logged here\n",
    "        self.log(\"valid_loss\", loss, prog_bar=True)\n",
    "        # There are no batches for the validatio step, so we directly compute the accuracy\n",
    "        self.log(\"valid_acc\", self.accuracy_valid.compute(), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Similar as validation_step()\n",
    "        X, y = batch\n",
    "        logits = self(X)\n",
    "        loss = torch.nn.functional.cross_entropy(self(X), y)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        self.accuracy_test.update(pred, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        self.log(\"test_acc\", self.accuracy_test.compute(), prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Define an optimizer\n",
    "        # Note that the name is 'configure_optimizers', not 'configure_optimizer'!!\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f18e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "349360a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the model output\n",
    "model_test = MultiLayerPerceptron()\n",
    "# Generate data that mimic 2 images, each of size 1-28-28\n",
    "images = torch.randn(2, 1, 28, 28)\n",
    "# The output for each image contains 10 logits.\n",
    "model_test(images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fac59ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4901, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test the loss function\n",
    "y = torch.tensor([1,2])\n",
    "logits = model_test(images)\n",
    "loss = torch.nn.functional.cross_entropy(logits, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5b4159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Test the prediction\n",
    "pred = torch.argmax(logits, dim=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af2839",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab789bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_path='./data'):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        # Note that this following result is not assigned to any variable\n",
    "        # Its function is only to download the dataset.\n",
    "        torchvision.datasets.MNIST(root=self.data_path)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        # stage = 'fit' or 'validate' or 'test' or 'predict'\n",
    "        mnist_all = torchvision.datasets.MNIST(\n",
    "            root=self.data_path,\n",
    "            train=True,\n",
    "            transform=self.transform,\n",
    "            download=False\n",
    "        )\n",
    "        \n",
    "        # mnist_all contains the training and validation datasets\n",
    "        # So we split it. The two datasets have 55000 and 5000 examples respectively.\n",
    "        # To randomly split the data, we need a generator\n",
    "        # We create the generator by using torch.Generator() \n",
    "        # and use its manual_seed method to get reproducible result.\n",
    "        self.train, self.val = torch.utils.data.random_split(\n",
    "            mnist_all, [55000, 5000], generator=torch.Generator().manual_seed(1)\n",
    "        )\n",
    "        \n",
    "        # Create the test set\n",
    "        self.test = torchvision.datasets.MNIST(\n",
    "            root=self.data_path,\n",
    "            train=False,\n",
    "            transform=self.transform,\n",
    "            download=False\n",
    "        )\n",
    "        \n",
    "    def train_dataloader(self): \n",
    "        # By using the num_workers=4, \n",
    "        # the data loading will be performed in parallel in 4 subprocesses.\n",
    "        return torch.utils.data.DataLoader(self.train, batch_size=64, num_workers=4)\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val, batch_size=64, num_workers=4)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.test, batch_size=64, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d5e9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "mnist_dm = MnistDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "91681833",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier = MultiLayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d036a6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    trainer = pl.Trainer(max_epochs=20, accelerator=\"gpu\", devices=1)\n",
    "else:\n",
    "    trainer = pl.Trainer(max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97e08f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 2050') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | accuracy_train | MulticlassAccuracy | 0     \n",
      "1 | accuracy_valid | MulticlassAccuracy | 0     \n",
      "2 | accuracy_test  | MulticlassAccuracy | 0     \n",
      "3 | model          | Sequential         | 25.8 K\n",
      "------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f747836d4b744445a6959dec4cb13a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=mnist_classifier, datamodule=mnist_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab468894",
   "metadata": {},
   "source": [
    "## Tensor Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31aa9fe5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15148), started 0:24:07 ago. (Use '!kill 15148' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7b47d518c8cd721c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7b47d518c8cd721c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65cd0668",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_classifier_continue = MultiLayerPerceptron.load_from_checkpoint('./lightning_logs/version_9/checkpoints/epoch=19-step=17200.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "46185bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    trainer = pl.Trainer(max_epochs=5, accelerator=\"gpu\", devices=1)\n",
    "else:\n",
    "    trainer = pl.Trainer(max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "776e949d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 2050') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | accuracy_train | MulticlassAccuracy | 0     \n",
      "1 | accuracy_valid | MulticlassAccuracy | 0     \n",
      "2 | accuracy_test  | MulticlassAccuracy | 0     \n",
      "3 | model          | Sequential         | 25.8 K\n",
      "------------------------------------------------------\n",
      "25.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.8 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164ff7dfb0c74d9ab68c2bb1edffa188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=mnist_classifier_continue, datamodule=mnist_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4da37d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15148), started 0:35:57 ago. (Use '!kill 15148' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a8ce459f849de09b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a8ce459f849de09b\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09d25691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 2050') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1d8b742ba2c4901ab5eaf05510edcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "       Test metric             DataLoader 0\r\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\r\n",
      "        test_acc            0.9504699110984802\r\n",
      "        test_loss           0.17379100620746613\r\n",
      "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.17379100620746613, 'test_acc': 0.9504699110984802}]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model performance on the test set\n",
    "trainer.test(model=mnist_classifier_continue, datamodule=mnist_dm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
