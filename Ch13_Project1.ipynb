{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3da8469",
   "metadata": {},
   "source": [
    "## Predicting fuel efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b278f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "# Note that importing 'sklearn' will not automatically import the submodel 'model_selection'\n",
    "import sklearn.model_selection \n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b9d029",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55780fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin  car name  \n",
       "0            70       1       NaN  \n",
       "1            70       1       NaN  \n",
       "2            70       1       NaN  \n",
       "3            70       1       NaN  \n",
       "4            70       1       NaN  \n",
       "..          ...     ...       ...  \n",
       "393          82       1       NaN  \n",
       "394          82       2       NaN  \n",
       "395          82       1       NaN  \n",
       "396          82       1       NaN  \n",
       "397          82       1       NaN  \n",
       "\n",
       "[398 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', \n",
    "                 'acceleration', 'model year', 'origin', 'car name']\n",
    "df = pd.read_csv('data/auto-mpg.data', header=None, names=feature_names, na_values='?', comment='\\t',\n",
    "sep=\" \", skipinitialspace=True)\n",
    "df\n",
    "\n",
    "# Two questions here:\n",
    "# (1) why is comment='\\t' used here, since there are no comment lines.\n",
    "# (2) The car names in the file are stored as \"...\", with the quote marks explicitly in the file.\n",
    "#     How to read these car names? Currently, they are shown as NaN.\n",
    "\n",
    "\n",
    "# Possible answer to (1):\n",
    "# At the end of each line in the data file, there is a car name stored as \"abc\". \n",
    "# In front of it, there is a tab. I guess that comment='\\t' makes pd.read_csv ignore the car name.\n",
    "\n",
    "# Possible answer to (2): see the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca46f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "      <th>car name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford mustang gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>dodge rampage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>ford ranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0    18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1    15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2    18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3    16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4    17.0          8         302.0       140.0  3449.0          10.5   \n",
       "..    ...        ...           ...         ...     ...           ...   \n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     model year  origin                   car name  \n",
       "0            70       1  chevrolet chevelle malibu  \n",
       "1            70       1          buick skylark 320  \n",
       "2            70       1         plymouth satellite  \n",
       "3            70       1              amc rebel sst  \n",
       "4            70       1                ford torino  \n",
       "..          ...     ...                        ...  \n",
       "393          82       1            ford mustang gl  \n",
       "394          82       2                  vw pickup  \n",
       "395          82       1              dodge rampage  \n",
       "396          82       1                ford ranger  \n",
       "397          82       1                 chevy s-10  \n",
       "\n",
       "[398 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This read all the data, including the car names.\n",
    "df = pd.read_csv('data/auto-mpg.data', \n",
    "                 delim_whitespace=True, \n",
    "                 header=None, \n",
    "                 names=['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name'],\n",
    "                 na_values='?')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a8b71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing data\n",
    "df = df.dropna()\n",
    "# Note that when we loaded the data, we use the option na_values='?'.\n",
    "# Without this option, df.dropna will not drop the rows containing '?'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d44dcd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "# df.reset_index() turns the old indices as a column and adds new integer indices.\n",
    "# df.reset_index(drop=True): use the drop parameter to avoid the old index being added as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9a1e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'horsepower' power column seems to contain float numbers.\n",
    "# But the values are of type 'object'.\n",
    "# Here we change them to float\n",
    "\n",
    "# Update!!\n",
    "# This cell is abandoned. The reason is that previously without na_values='?', the dataframe contains\n",
    "#     '?' even after df.dropna(). As a result, the column df['horsepower'] has 'object' as its datatype.\n",
    "#     When the rows containing '?' are correctly dropped, df['horsepower'] naturally becomes\n",
    "#     a column of type 'float'. So there is no need to use pd.to_numeric\n",
    "\n",
    "# df['horsepower'] = pd.to_numeric(df['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130a68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# Previously, we needed to provide both the features X and the labels y\n",
    "# Now we provide a pandas dataframe\n",
    "df_train, df_test = sklearn.model_selection.train_test_split(df, train_size=0.8, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1054a566",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model year</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.404153</td>\n",
       "      <td>5.402556</td>\n",
       "      <td>189.512780</td>\n",
       "      <td>102.929712</td>\n",
       "      <td>2961.198083</td>\n",
       "      <td>15.704473</td>\n",
       "      <td>75.929712</td>\n",
       "      <td>1.591054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.666909</td>\n",
       "      <td>1.701506</td>\n",
       "      <td>102.675646</td>\n",
       "      <td>37.919046</td>\n",
       "      <td>848.602146</td>\n",
       "      <td>2.725399</td>\n",
       "      <td>3.675305</td>\n",
       "      <td>0.807923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>1613.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2219.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>2755.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3574.000000</td>\n",
       "      <td>17.300000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>46.600000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>5140.000000</td>\n",
       "      <td>24.800000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mpg   cylinders  displacement  horsepower       weight  \\\n",
       "count  313.000000  313.000000    313.000000  313.000000   313.000000   \n",
       "mean    23.404153    5.402556    189.512780  102.929712  2961.198083   \n",
       "std      7.666909    1.701506    102.675646   37.919046   848.602146   \n",
       "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
       "25%     17.500000    4.000000    104.000000   75.000000  2219.000000   \n",
       "50%     23.000000    4.000000    140.000000   92.000000  2755.000000   \n",
       "75%     29.000000    8.000000    260.000000  120.000000  3574.000000   \n",
       "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
       "\n",
       "       acceleration  model year      origin  \n",
       "count    313.000000  313.000000  313.000000  \n",
       "mean      15.704473   75.929712    1.591054  \n",
       "std        2.725399    3.675305    0.807923  \n",
       "min        8.500000   70.000000    1.000000  \n",
       "25%       14.000000   73.000000    1.000000  \n",
       "50%       15.500000   76.000000    1.000000  \n",
       "75%       17.300000   79.000000    2.000000  \n",
       "max       24.800000   82.000000    3.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe.describe(): provide summary statistics\n",
    "df_train_stats = df_train.describe()\n",
    "df_train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71377774",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "# Prepare a list of feature names corresponding to numerical (not categorical) values\n",
    "feature_name_numeric = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration']\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "for feature in feature_name_numeric:\n",
    "    mean = df_train_stats.loc['mean', feature]\n",
    "    std = df_train_stats.loc['std', feature]\n",
    "    df_train_norm[feature] = (df_train_norm[feature] - mean) / std\n",
    "    df_test_norm[feature] = (df_test_norm[feature] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6340eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change model year to ordered labels (bucketing)\n",
    "boundaries = torch.tensor([73, 76, 79])\n",
    "v = torch.tensor(df_train_norm['model year'].values)\n",
    "df_train_norm['model year bucketed'] = torch.bucketize(v, boundaries, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f23c41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor(df_test_norm['model year'].values)\n",
    "df_test_norm['model year bucketed'] = torch.bucketize(v, boundaries, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab78425f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 2, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Explanation on torch.bucketize\n",
    "\n",
    "# Prepare a test data set\n",
    "test_data = torch.tensor([1.0, 2.5, 3.0, 4.2, 5.1, 6.8, 7.1])\n",
    "# Boundaries of the bins\n",
    "# Note that these are inner boundaries. The left boundary of the first bin is -inf.\n",
    "# The right boundary of the last bin is inf.\n",
    "# Here four inner boundaries are set, so there will be 5 bins, indexed as 0, 1, 2, 3, 4.\n",
    "bins = torch.tensor([1.0, 3.0, 5.0, 7.0])\n",
    "# Put data into different bins\n",
    "# right=False: the right boundary of each bin is exclusive\n",
    "label_bins = torch.bucketize(test_data, bins, right=False)\n",
    "print(label_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065758d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the bucket column name to the list 'feature_name_numeric'\n",
    "feature_name_numeric.append('model year bucketed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11354255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "num_origin = len(set(df_train_norm['origin'])) # See below for explanation on 'set'\n",
    "num_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d96fc7ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set(): returns the unique elements\n",
    "set(df_train_norm['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6d8550f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n",
      "tensor([[1, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0],\n",
      "        [0, 0, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 0],\n",
      "        [0, 0, 0, 0, 1]])\n"
     ]
    }
   ],
   "source": [
    "# About torch.nn.functional.one_hot\n",
    "# The simplest example\n",
    "print(torch.arange(0, 5))\n",
    "print(torch.nn.functional.one_hot(torch.arange(0, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c78a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 3, 2, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3,\n",
       "       1, 1, 3, 2, 3, 1, 3, 1, 1, 3, 2, 3, 1, 1, 1, 1, 1, 2, 1, 2, 3, 2,\n",
       "       3, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 2, 1, 1, 2,\n",
       "       1, 2, 1, 1, 3, 2, 3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 3,\n",
       "       2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 3, 3, 1, 1, 1,\n",
       "       1, 1, 1, 3, 2, 1, 1, 3, 1, 1, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1,\n",
       "       1, 1, 1, 3, 3, 2, 3, 3, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1,\n",
       "       1, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 3, 3, 3, 1, 1, 1, 3, 2,\n",
       "       1, 1, 3, 1, 3, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 3, 3, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 2, 1,\n",
       "       2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 3, 3,\n",
       "       3, 1, 1, 1, 3, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3,\n",
       "       1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 3, 1, 1, 2, 3,\n",
       "       3, 1, 2, 1, 3, 3, 1, 1, 2, 1, 1, 3, 1, 2, 2, 1, 3, 1, 3, 1, 1, 1,\n",
       "       3, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional.one_hot only accepts tensor as input\n",
    "# df_train_norm['origin'] is a pandas series\n",
    "# We need to convert it into a tensor\n",
    "\n",
    "# First note that the original values for 'origin' are 1,2,3\n",
    "df_train_norm['origin'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0dc14a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.nn.functional.one_hot expects indices starting from 0\n",
    "# So we subtract by 1, convert the result into a tensor, and pass it to torch.nn.functional.one_hot\n",
    "torch.nn.functional.one_hot(torch.tensor(df_train_norm['origin'].values - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7aa4465",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we don't substract 1, the resulting one-hot label will have 4 entries in each row\n",
    "torch.nn.functional.one_hot(torch.tensor(df_train_norm['origin'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fd0c32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are ready to apply one-hot encoding\n",
    "# First we encode the labels in column 'origin'\n",
    "one_hot_labels = torch.nn.functional.one_hot(torch.tensor(df_train_norm['origin'].values - 1))\n",
    "one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ab5eca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.2430e-01, -5.3092e-01, -4.9921e-01, -5.5526e-01, -1.6412e-03,\n",
       "          3.0000e+00],\n",
       "        [ 3.5113e-01,  3.4562e-01,  1.8646e-01,  7.7634e-01,  1.0991e+00,\n",
       "          2.0000e+00],\n",
       "        [-8.2430e-01, -8.9128e-01, -5.2559e-01, -8.7461e-01,  2.9189e-01,\n",
       "          1.0000e+00],\n",
       "        ...,\n",
       "        [ 1.5266e+00,  1.1443e+00,  7.1390e-01,  1.3396e+00, -6.2540e-01,\n",
       "          0.0000e+00],\n",
       "        [-8.2430e-01, -8.9128e-01, -1.0530e+00, -1.0726e+00,  4.7535e-01,\n",
       "          2.0000e+00],\n",
       "        [ 1.5266e+00,  1.5631e+00,  1.6369e+00,  1.4704e+00, -1.3592e+00,\n",
       "          0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we create another tensor from numerical values in df_train_norm\n",
    "X_train_numeric = torch.tensor(df_train_norm[feature_name_numeric].values)\n",
    "X_train_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "88334cf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8243, -0.5309, -0.4992,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 0.3511,  0.3456,  0.1865,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [-0.8243, -0.8913, -0.5256,  ...,  0.0000,  1.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 1.5266,  1.1443,  0.7139,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [-0.8243, -0.8913, -1.0530,  ...,  1.0000,  0.0000,  0.0000],\n",
       "        [ 1.5266,  1.5631,  1.6369,  ...,  1.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to concatenate the numeric features with the one-hot labels\n",
    "X_train = torch.cat([X_train_numeric, one_hot_labels], dim=1)\n",
    "# This code converts the entries in X_train into float32\n",
    "# This is a tricky step. By default, the weight matrices generated by torch.nn.Sequential is of float32.\n",
    "# If the training data is not float32, there will be an error when doing forward propagation.\n",
    "X_train = X_train.float()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5b4d1697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8243, -0.6770, -0.1564, -0.5364, -0.4419,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.9010, -0.7366, -0.9312,  0.1084,  1.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.7939, -0.7366, -0.7202,  0.4020,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.6673,  0.2392, -0.1098, -0.0750,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9595, -0.9475, -1.1386,  0.1818,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.8913, -0.5256, -1.0443,  0.0717,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9108, -0.8948, -0.9100,  0.8423,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.2514,  1.2413,  1.5034, -0.4419,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9010, -0.2882, -0.7933,  0.4754,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.8036, -0.8157, -0.7909,  0.4754,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 0.3511,  0.4041,  0.3183,  0.3344, -0.1117,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.8913, -0.7102, -0.9630, -0.3686,  3.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.1248,  0.7139,  1.0356, -0.1117,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -1.0179, -0.8684, -1.1975,  0.4020,  2.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.5309, -0.4992, -0.5140,  0.1084,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.0956,  0.9776,  0.5748, -1.9096,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.5309, -0.4992, -0.6967, -0.9923,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9692, -1.4486, -0.7379,  2.9337,  3.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.5759,  3.0874,  1.6413, -2.4600,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4138, -0.0773, -0.0556,  0.1084,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.7160, -0.7366, -0.8428, -0.6254,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.6670,  0.1865,  0.7905,  0.8423,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.2514,  1.2413,  0.5159, -1.7262,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.5631,  1.7688,  1.4186, -1.5794,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.3325,  2.5072,  1.6260, -2.0931,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.6604,  1.2413,  1.1534, -0.9923,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.8913, -0.9212, -1.0797,  1.0257,  2.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 0.3511,  0.3456, -0.0773,  0.8129,  0.7322,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4041,  0.1865,  0.0917, -0.2585,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.5309, -0.4992, -0.6790, -1.0290,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.1248,  1.1095,  0.5465, -0.9189,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.3751, -0.3937, -0.2607,  0.1084,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.5631,  1.3732,  1.8157, -0.8089,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4138,  0.2392, -0.1487, -0.3686,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4041,  0.0546,  0.5465,  0.4387,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.1248,  0.9776,  1.4775, -0.9923,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.3456, -0.2091,  0.9708,  1.2092,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4041,  0.0546,  0.6762,  1.2826,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9595, -0.9475, -1.1739, -0.2585,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [-0.8243, -0.9010, -0.3937, -0.9795, -0.4419,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 1.5266,  2.0500,  2.2962,  1.6071, -1.2859,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.0500,  1.9006,  1.6778, -1.3592,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511, -0.3264,  0.5029, -0.1817, -0.8089,  0.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 0.3511,  0.4138, -0.0773, -0.0709,  0.1084,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4138, -0.0773, -0.2029, -0.2585,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.6670,  0.1865,  0.9060,  1.2092,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.0500,  1.2413,  2.3990, -0.6254,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9595, -0.9212, -1.1680,  0.6955,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 0.3511,  0.3456, -0.0773,  0.3203, -0.1117,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.4396,  2.9555,  2.0903, -1.7262,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.1150,  1.2413,  0.8376, -1.5427,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.1021, -0.2091,  0.2284,  0.9157,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.3751, -0.3410, -0.3337,  0.2919,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.5309, -0.4992, -0.7851, -1.5060,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9789, -1.0794, -1.3153, -0.1484,  3.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511, -0.1803, -0.1564,  0.0269, -0.4419,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511, -0.1608,  0.3183, -0.4315, -1.6161,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.1021, -0.4728, -0.4410,  0.1084,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.3751, -0.3410, -0.4775, -0.9189,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9595, -1.1321, -1.3684,  0.2552,  2.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 0.3511,  0.7060, -0.4728,  0.0634,  0.4754,  3.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.8036, -0.4465, -0.5859, -0.0750,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -1.0179, -1.0003, -1.1621,  1.3560,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 1.5266,  0.6865,  0.1865,  0.4758, -0.0750,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4138, -0.3410,  0.1459,  0.6955,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 0.3511,  0.4138, -0.3410,  0.2944,  0.4754,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.6770, -0.3937,  0.3639,  2.2733,  1.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.4657,  1.5051,  0.7634, -2.8269,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9789, -0.8420, -1.2211, -0.6254,  2.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.8845,  2.0325,  2.3495, -1.5427,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.6868, -0.2882, -0.6213, -0.2585,  3.0000,  0.0000,  0.0000,\n",
       "          1.0000],\n",
       "        [ 1.5266,  0.7547,  0.5820,  0.7587, -0.2585,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.2514,  1.2413,  0.9354, -0.6254,  1.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.9010, -0.6574, -0.9111,  0.0351,  3.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.6673,  0.2656, -0.8569, -1.1758,  0.0000,  0.0000,  1.0000,\n",
       "          0.0000],\n",
       "        [-0.8243, -0.8913, -0.6047, -1.2328, -0.4786,  2.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.5857,  3.2192,  0.1471, -2.0931,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  2.0500,  1.2413,  1.7709, -1.3592,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000],\n",
       "        [ 1.5266,  1.5631,  1.6369,  1.5470, -1.3592,  0.0000,  1.0000,  0.0000,\n",
       "          0.0000]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We follow the same steps to create the test data\n",
    "one_hot_labels_test = torch.nn.functional.one_hot(torch.tensor(df_test_norm['origin'].values - 1))\n",
    "X_test_numeric = torch.tensor(df_test_norm[feature_name_numeric].values)\n",
    "X_test = torch.cat([X_test_numeric, one_hot_labels_test], dim=1)\n",
    "X_test = X_test.float()\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "159d92cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27.2000, 18.6000, 29.0000, 37.2000, 33.0000, 13.0000, 22.4000, 44.6000,\n",
       "        27.4000, 31.0000, 24.0000, 28.0000, 17.6000, 15.0000, 11.0000, 12.0000,\n",
       "        26.8000, 13.0000, 21.6000, 20.8000, 16.9000, 20.0000, 26.5000, 18.0000,\n",
       "        26.0000, 24.0000, 29.5000, 20.2000, 32.8000, 14.0000, 16.0000, 31.8000,\n",
       "        30.7000, 34.1000, 20.0000, 15.0000, 28.4000, 20.0000, 13.0000, 35.0000,\n",
       "        31.0000, 44.0000, 27.0000, 17.0000, 34.1000, 14.0000, 23.0000, 28.1000,\n",
       "        14.5000, 24.0000, 29.9000, 36.0000, 23.9000, 15.0000, 16.0000, 20.0000,\n",
       "        16.0000, 24.0000, 23.9000, 11.0000, 14.0000, 19.0000, 30.0000, 21.0000,\n",
       "        15.0000, 23.0000, 18.0000, 29.0000, 18.0000, 12.0000, 33.0000, 29.5000,\n",
       "        19.0000, 14.0000, 19.0000, 26.6000, 36.0000, 38.0000, 24.0000, 13.0000,\n",
       "        16.0000, 17.5000, 19.0000, 16.0000, 27.0000, 16.5000, 20.3000, 24.0000,\n",
       "        30.0000, 23.0000, 17.0000, 18.0000, 25.5000, 13.0000, 24.0000, 16.0000,\n",
       "        26.0000, 19.4000, 17.0000, 30.9000, 18.0000, 23.7000, 19.0000, 30.5000,\n",
       "        21.0000, 39.1000, 24.0000, 22.0000, 36.0000, 13.0000, 14.0000, 28.0000,\n",
       "        18.0000, 32.3000, 44.3000, 19.1000,  9.0000, 25.0000, 26.0000, 20.6000,\n",
       "        19.0000, 21.1000, 23.0000, 36.4000, 32.0000, 16.0000, 17.7000, 19.0000,\n",
       "        35.1000, 15.0000, 14.0000, 26.0000, 19.0000, 15.5000, 11.0000, 39.4000,\n",
       "        32.7000, 16.2000, 36.0000, 32.0000, 34.0000, 22.0000, 13.0000, 23.0000,\n",
       "        43.1000, 18.0000, 26.0000, 22.0000, 17.5000, 34.2000, 14.0000, 24.0000,\n",
       "        26.0000, 13.0000, 13.0000, 35.0000, 18.5000, 23.8000, 14.0000, 21.0000,\n",
       "        31.0000, 15.5000, 27.0000, 20.0000, 16.0000, 23.0000, 29.0000, 13.0000,\n",
       "        25.4000, 31.0000, 37.0000, 23.5000, 13.0000, 20.2000, 37.7000, 29.0000,\n",
       "        26.4000, 25.5000, 24.0000, 32.1000, 40.8000, 18.2000, 25.0000, 16.0000,\n",
       "        15.0000, 20.0000, 25.4000, 25.0000, 39.0000, 27.0000, 23.0000, 24.5000,\n",
       "        18.0000, 25.0000, 27.9000, 12.0000, 17.0000, 25.0000, 17.6000, 21.0000,\n",
       "        12.0000, 29.0000, 26.0000, 26.0000, 32.0000, 15.0000, 46.6000, 15.0000,\n",
       "        23.2000, 18.0000, 16.5000, 21.5000, 25.0000, 34.5000, 18.0000, 31.6000,\n",
       "        25.0000, 34.4000, 18.0000, 17.5000, 21.0000, 17.5000, 27.0000, 31.0000,\n",
       "        34.7000, 18.0000, 31.0000, 18.1000, 25.1000, 18.1000, 26.0000, 18.0000,\n",
       "        34.0000, 37.3000, 22.0000, 14.0000, 36.1000, 25.0000, 14.0000, 22.0000,\n",
       "        32.0000, 33.8000, 27.2000, 15.5000, 14.0000, 23.0000, 27.0000, 33.7000,\n",
       "        15.0000, 19.8000, 15.0000, 29.0000, 27.5000, 27.0000, 13.0000, 15.0000,\n",
       "        20.6000, 18.5000, 10.0000, 33.0000, 14.0000, 22.0000, 27.2000, 22.0000,\n",
       "        25.8000, 38.1000, 10.0000, 22.0000, 13.0000, 22.3000, 16.0000, 28.0000,\n",
       "        28.0000, 26.0000, 28.0000, 24.0000, 16.0000, 27.0000, 36.0000, 30.0000,\n",
       "        16.5000, 29.8000, 15.0000, 24.3000, 25.0000, 31.3000, 32.2000, 14.0000,\n",
       "        26.0000, 13.0000, 32.9000, 21.5000, 30.0000, 12.0000, 30.0000, 16.0000,\n",
       "        20.2000, 24.2000, 20.5000, 31.5000, 25.0000, 20.2000, 30.0000, 15.0000,\n",
       "        32.0000, 28.0000, 26.6000, 18.0000, 28.0000, 19.4000, 13.0000, 30.5000,\n",
       "        14.0000])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now the features are prepared.\n",
    "# We still need to create target labels, which is the mpg data\n",
    "y_train = torch.tensor(df_train_norm['mpg'].values)\n",
    "y_train = y_train.float()\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82b9797d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([23.0000, 29.0000, 32.4000, 19.0000, 38.0000, 33.5000, 26.0000, 14.0000,\n",
       "        28.0000, 32.4000, 21.5000, 41.5000, 17.0000, 33.5000, 29.0000, 17.0000,\n",
       "        36.0000, 43.4000, 14.0000, 20.0000, 26.0000, 16.0000, 15.0000, 15.5000,\n",
       "        15.0000, 18.5000, 31.5000, 20.0000, 21.0000, 30.0000, 19.2000, 24.5000,\n",
       "        13.0000, 22.0000, 20.5000, 17.5000, 18.0000, 19.2000, 38.0000, 27.0000,\n",
       "        15.5000, 14.0000, 20.0000, 19.0000, 18.0000, 15.0000, 11.0000, 31.0000,\n",
       "        22.0000, 13.0000, 17.0000, 20.5000, 28.0000, 32.0000, 29.8000, 18.0000,\n",
       "        28.8000, 21.0000, 33.5000, 36.1000, 38.0000, 28.0000, 37.0000, 19.9000,\n",
       "        22.5000, 19.0000, 19.0000, 14.0000, 31.9000, 12.0000, 37.0000, 19.2000,\n",
       "        13.0000, 34.3000, 26.0000, 35.7000, 14.0000, 13.0000, 13.0000])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = torch.tensor(df_test_norm['mpg'].values)\n",
    "y_test = y_test.float()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228920c5",
   "metadata": {},
   "source": [
    "# Training a Dense Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3ec79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dataset\n",
    "dataset_train =  torch.utils.data.TensorDataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7ae08f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dataloader\n",
    "torch.manual_seed(1)\n",
    "batch_size = 8\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8bf08d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dense network\n",
    "# The first hidden layer has 8 neurons\n",
    "# The second hidden layer has 4 neurons\n",
    "# The output layer is simply a linear layer with scalar output, since this is a regression problem.\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(torch.nn.Linear(input_size,8),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(8, 4),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(4, 1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ee78e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "# Define an optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a2b0fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 534.3643589446339\n",
      "Epoch 20, Loss 7.06433017609028\n",
      "Epoch 40, Loss 6.552436389862158\n",
      "Epoch 60, Loss 6.635329810194314\n",
      "Epoch 80, Loss 6.227665164885811\n",
      "Epoch 100, Loss 6.456776005772356\n",
      "Epoch 120, Loss 6.389741701059068\n",
      "Epoch 140, Loss 5.664601301613708\n",
      "Epoch 160, Loss 5.565009224172027\n",
      "Epoch 180, Loss 5.4943155313071355\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epoch = 200\n",
    "log_epoch = 20\n",
    "\n",
    "loss_history_train = []\n",
    "loss_history_test = []\n",
    "\n",
    "num_train = len(X_train)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    # Loss for all training data\n",
    "    loss_train = 0\n",
    "    for X_batch, y_batch in dataloader_train:\n",
    "        pred = model(X_batch)[:, 0]\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # loss is a tensor. We need to extract its value by using item()\n",
    "        loss_train += loss.item() * len(X_batch)\n",
    "    loss_train /= num_train\n",
    "    loss_history_train.append(loss_train)\n",
    "    \n",
    "    pred = model(X_test)[:,0]\n",
    "    loss_test = loss_fn(pred, y_test)\n",
    "    loss_history_test.append(loss_test.item())\n",
    "    \n",
    "    if epoch % log_epoch == 0:\n",
    "        print(f'Epoch {epoch}, Loss {loss_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "97180af7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x268e284c880>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss for the training and test datasets\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(loss_history_train, label=\"Loss_train\")\n",
    "ax.plot(loss_history_test, label=\"Loss_test\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
